from dotenv import load_dotenv
import os
import openai
import json
import sys
import sounddevice as sd
import scipy.io.wavfile as wav
from tempfile import NamedTemporaryFile
from tenacity import retry, stop_after_attempt, wait_random_exponential
from openai import OpenAI
import base64
from io import BytesIO
from PIL import Image
import urllib.request

# Load environment variables
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    print("âŒ Error: OPENAI_API_KEY not found in environment variables.")
    exit(1)

client = OpenAI(api_key=api_key)

# System prompt for DALLÂ·E image generation chatbot
SYSTEM_PROMPT = (
    "You are Glimmcatcher, a highly creative DALLÂ·E-powered image generation assistant. "
    "Your role is to interpret user inputs and craft vivid, detailed, and imaginative image descriptions for DALLÂ·E to generate stunning visuals. "
    "Enhance vague or simple requests with rich details, such as mood, lighting, style (e.g., photorealistic, surreal, watercolor), and context, while staying true to the user's intent. "
    "If the input is unclear, generate a refined prompt with creative suggestions, but always confirm alignment with the user's vision. "
    "Provide concise, engaging responses, and ensure the generated images are safe, ethical, and visually compelling. "
    "If the request is not about generating images, simply reply appropriately and do not attempt image generation."
)

# Prompt and response cache for efficiency
prompt_cache = {}
response_cache = {}

# Audio recording and transcription
def record_audio(duration=5, samplerate=44100):
    print(f"ğŸ™ï¸ Recording for {duration} seconds...")
    try:
        recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1)
        sd.wait()
        temp_file = NamedTemporaryFile(delete=False, suffix=".wav")
        wav.write(temp_file.name, samplerate, recording)
        print("âœ… Recording saved.")
        return temp_file.name
    except Exception as e:
        print(f"âŒ Error recording audio: {str(e)}")
        return None

def transcribe_audio(audio_path):
    print("ğŸ§  Transcribing audio...")
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="en"
            )
        return transcript.text
    except Exception as e:
        print(f"âŒ Error transcribing audio: {str(e)}")
        return None

# Image generation with DALLÂ·E
@retry(stop=stop_after_attempt(3), wait=wait_random_exponential(min=1, max=5))
def generate_image(description):
    if not description.strip():
        return "â— Please provide a valid image description."
    if description in response_cache:
        return response_cache[description]

    try:
        print("ğŸ–¼ï¸ Generating image with DALLÂ·E...")
        response = client.images.generate(
            model="dall-e-3",
            prompt=description,
            size="1024x1024",
            quality="standard",
            n=1
        )
        image_url = response.data[0].url
        response_cache[description] = image_url
        return image_url
    except openai.OpenAIError as e:
        return f"âŒ OpenAI API Error: {str(e)}"
    except Exception as e:
        return f"âŒ Unexpected Error: {str(e)}"

# Save image locally
def save_image(image_url, filename="generated_image.png"):
    try:
        urllib.request.urlretrieve(image_url, filename)
        print(f"âœ… Image saved as {filename}")
        return filename
    except Exception as e:
        print(f"âŒ Error saving image: {str(e)}")
        return None

# Chatbot logic with DALLÂ·E
@retry(stop=stop_after_attempt(3), wait=wait_random_exponential(min=1, max=5))
def ask_image_assistant(user_input):
    if not SYSTEM_PROMPT:
        return "System prompt could not be loaded."
    if not user_input.strip():
        return "â— Please provide a valid description."

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_input}
    ]

    try:
        # First, get a refined description from the chat model
        response = stream_chat_response(messages)
        if "âŒ" in response:
            return response
        
        # Generate image based on the refined description
        image_url = generate_image(response)
        if "âŒ" in image_url:
            return image_url
        
        # Save the image locally
        saved_image = save_image(image_url)
        if saved_image:
            return f"âœ… Image generated and saved as {saved_image}. URL: {image_url}"
        else:
            return f"âœ… Image generated. URL: {image_url}"
    except Exception as e:
        return f"âŒ Unexpected Error: {str(e)}"

def stream_chat_response(conversation, model="gpt-4-turbo", temperature=0.7, max_tokens=800):
    assistant_reply = ""
    try:
        response_stream = client.chat.completions.create(
            model=model,
            messages=conversation,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=True
        )
        for chunk in response_stream:
            if hasattr(chunk, "choices") and chunk.choices:
                delta = chunk.choices[0].delta
                content = getattr(delta, "content", None)
                if content:
                    print(content, end="", flush=True)
                    assistant_reply += content
        print()  # New line after streaming
        return assistant_reply
    except Exception as e:
        return f"âŒ Error generating response: {e}"

# CLI with text/voice support
def run_chat_loop():
    while True:
        try:
            mode = input("\nType 'text' to type a description, 'voice' to speak, or 'exit' to quit: ").strip().lower()
            if mode == "exit":
                print("ğŸ‘‹ Goodbye!")
                break
            elif mode == "voice":
                audio_path = record_audio(duration=5)
                if audio_path:
                    user_input = transcribe_audio(audio_path)
                    if user_input:
                        print("ğŸ—£ï¸ You said:", user_input)
                    else:
                        print("âŒ Failed to transcribe audio.")
                        continue
                else:
                    print("âŒ Failed to record audio.")
                    continue
            elif mode == "text":
                user_input = input("Type your image description: ")
            else:
                print("âš ï¸ Invalid input. Choose 'text', 'voice', or 'exit'.")
                continue

            response = ask_image_assistant(user_input)
            print("\nğŸ¤– Image Assistant:", response)

        except KeyboardInterrupt:
            print("\nâ— Interrupted by user. Exiting...")
            break
        except Exception as e:
            print(f"âŒ Error: {str(e)}")

# Main
if __name__ == "__main__":
    if len(sys.argv) > 1:
        user_input = " ".join(sys.argv[1:])
        answer = ask_image_assistant(user_input)
        print("Image Assistant:", answer)
    else:
        run_chat_loop() 



